#! /usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import print_function


import argparse
from argparse import RawTextHelpFormatter
import os
import shutil
import cv2

from deep_ocr.captcha.char_segmentation import CharSegmentation
from deep_ocr.captcha.search_best_segmentation import SearchBestSegmentation
from deep_ocr.caffe_clf import CaffeCls
from deep_ocr.cv2_img_proc import PreprocessResizeKeepRatio


if __name__ == "__main__":

    description = '''
        # Docker config
        CAFFE_MODEL=/opt/deep_ocr/data/trained_models/mnist_model
        DEEP_OCR_ROOT=/opt/deep_ocr
        
        # PC
        CAFFE_MODEL=/root/data/deep_ocr_trained_models/mnist_model
        DEEP_OCR_ROOT=/root/workspace/deep_ocr

        deep_ocr_reco_captcha --captcha_img $DEEP_OCR_ROOT/data/captcha/captcha.png \
            --num_char 5 \
            --caffe_model $CAFFE_MODEL/lenet_iter_10000.caffemodel \
            --caffe_network $CAFFE_MODEL/lenet.prototxt \
            --y_tag $CAFFE_MODEL/deep_ocr_network.y_tag.json \
            --caffe_img_w 28 --caffe_img_h 28 \
            --debug_path /tmp/debug_captcha

        deep_ocr_reco_captcha --captcha_img $DEEP_OCR_ROOT/data/captcha/simple.png \
            --num_char 5 \
            --caffe_model $CAFFE_MODEL/lenet_iter_10000.caffemodel \
            --caffe_network $CAFFE_MODEL/lenet.prototxt \
            --y_tag $CAFFE_MODEL/deep_ocr_network.y_tag.json \
            --caffe_img_w 28 --caffe_img_h 28 \
            --debug_path /tmp/debug_captcha

    '''

    parser = argparse.ArgumentParser(
        description=description, formatter_class=RawTextHelpFormatter)
    parser.add_argument('--captcha_img', dest='captcha_img',
                        default=None, required=True,
                        help='captcha image to reco')
    parser.add_argument('--num_char', dest='num_char',
                        default=None, required=True,
                        help='m_char')
    parser.add_argument('--caffe_model', dest='caffe_model',
                        default=None, required=True,
                        help='trained caffe model')
    parser.add_argument('--caffe_network', dest='caffe_network',
                        default=None, required=True,
                        help='caffe network')
    parser.add_argument('--y_tag', dest='y_tag',
                        default=None, required=True,
                        help='y_tag')
    parser.add_argument('--caffe_img_w', dest='caffe_img_w',
                        default=None, required=True,
                        help='caffe_img_w')
    parser.add_argument('--caffe_img_h', dest='caffe_img_h',
                        default=None, required=True,
                        help='caffe_img_h')
    parser.add_argument('--debug_path', dest='debug_path',
                        default=None, required=False,
                        help='debug path')
    options = parser.parse_args()

    captcha_img = os.path.expanduser(options.captcha_img)
    num_char = int(options.num_char)
    caffe_model = os.path.expanduser(options.caffe_model)
    caffe_network = os.path.expanduser(options.caffe_network)
    y_tag = os.path.expanduser(options.y_tag)
    caffe_img_w = int(options.caffe_img_w)
    caffe_img_h = int(options.caffe_img_h)
    norm_width = 200
    norm_height = 200

    debug_path = None
    if options.debug_path is not None:
        debug_path = os.path.expanduser(options.debug_path)
        if os.path.isdir(debug_path):
            shutil.rmtree(debug_path)
        os.makedirs(debug_path)

    image = cv2.imread(captcha_img)

    proc_keep_ratio = PreprocessResizeKeepRatio(
        width=norm_width, height=norm_height)
    image = proc_keep_ratio.do(image)

    char_segmentation = CharSegmentation(
        num_char=num_char,
        debug_path=debug_path)
    segmentations = char_segmentation.do(image)

    caffe_cls = CaffeCls(caffe_network, caffe_model, y_tag,
                         width=caffe_img_w, height=caffe_img_h)

    search_best_segmentation = SearchBestSegmentation(
        caffe_cls, char_segmentation.bin_img,
        debug_path)
    eval_segmentations = search_best_segmentation.do(segmentations)

    n_top = 100
    for i, eval_segmentation in enumerate(eval_segmentations):
        if i > n_top:
            break
        print(eval_segmentation)